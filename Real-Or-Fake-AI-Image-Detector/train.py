import os
import sys
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

# Fix encoding for Windows console
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# -----------------------
# CONFIG
# -----------------------
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 50  # Increased epochs for better training
DATASET_PATH = "dataset"
MODEL_PATH = "real_vs_ai_model.h5"

# Check if dataset exists
if not os.path.exists(DATASET_PATH):
    print("‚ùå Dataset folder not found!")
    print("Please run 'python prepare_dataset.py' first to download and prepare the dataset.")
    exit(1)

# -----------------------
# DATA PREPARATION
# -----------------------
print("üìä Preparing data with advanced augmentation...")

train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=15,  # Reduced rotation to preserve artifacts
    zoom_range=0.2,  # Reduced zoom
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    vertical_flip=False,  # Removed vertical flip to preserve artifacts
    brightness_range=[0.7, 1.3],  # Reduced brightness range
    shear_range=0.1,
    channel_shift_range=0.1,  # Reduced color channel shifts
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_data = train_datagen.flow_from_directory(
    DATASET_PATH,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
    subset="training",
    shuffle=True
)

val_data = val_datagen.flow_from_directory(
    DATASET_PATH,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
    subset="validation",
    shuffle=False
)

# Note: Classes are sorted alphabetically in flow_from_directory:
# "fake" = class 0 (AI Generated)
# "real" = class 1 (Human Prepared)
# Model output > 0.5 = class 1 (real/human), <= 0.5 = class 0 (fake/AI)

print(f"‚úÖ Training samples: {train_data.samples}")
print(f"‚úÖ Validation samples: {val_data.samples}")
print(f"‚úÖ Class indices: {train_data.class_indices}")

# Calculate class weights to handle imbalance
class_counts = {}
for class_name, class_idx in train_data.class_indices.items():
    # Count samples in training data
    class_dir = os.path.join(DATASET_PATH, class_name)
    if os.path.exists(class_dir):
        count = len([f for f in os.listdir(class_dir)
                    if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
        class_counts[class_idx] = count

# Calculate class weights (handle division by zero)
if len(class_counts) > 0 and sum(class_counts.values()) > 0:
    total_samples = sum(class_counts.values())
    class_weights = {}
    for class_idx, count in class_counts.items():
        if count > 0:
            class_weights[class_idx] = total_samples / \
                (len(class_counts) * count)
        else:
            class_weights[class_idx] = 1.0
    print(f"‚úÖ Class weights: {class_weights}")
else:
    class_weights = None
    print("‚ö†Ô∏è Could not calculate class weights, using default")

# -----------------------
# MODEL ARCHITECTURE
# -----------------------
print("\nüèóÔ∏è Building advanced model with fine-tuning capability...")

base_model = MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights="imagenet",
    alpha=1.0  # Full MobileNetV2
)

# Freeze base model initially
base_model.trainable = False

# Build model with optimized architecture for AI detection
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.BatchNormalization(),
    layers.Dense(512, activation="relu"),
    layers.Dropout(0.5),
    layers.BatchNormalization(),
    layers.Dense(256, activation="relu"),
    layers.Dropout(0.4),
    layers.BatchNormalization(),
    layers.Dense(128, activation="relu"),
    layers.Dropout(0.3),
    layers.Dense(1, activation="sigmoid")
])

# Note: Using standard metrics (accuracy, precision, recall)
# F1 score can be calculated from precision and recall if needed


# Initial compilation with frozen base
model.compile(
    optimizer=tf.keras.optimizers.Adam(
        learning_rate=0.0005),  # Lower initial LR for stability
    loss="binary_crossentropy",
    metrics=["accuracy", "precision", "recall"]
)

print("‚úÖ Model compiled successfully!")
model.summary()

# -----------------------
# CALLBACKS
# -----------------------
checkpoint = ModelCheckpoint(
    MODEL_PATH,
    monitor="val_accuracy",
    save_best_only=True,
    verbose=1,
    mode='max'
)

early_stopping = EarlyStopping(
    monitor="val_accuracy",
    patience=12,  # Increased patience
    restore_best_weights=True,
    verbose=1,
    mode='max'
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.3,  # Reduced factor for more gradual decrease
    patience=7,
    min_lr=1e-8,
    verbose=1
)

# -----------------------
# TRAINING PHASE 1: Train with frozen base
# -----------------------
print("\nüöÄ Phase 1: Training with frozen base model...")
print("=" * 50)

# Prepare fit arguments
fit_kwargs = {
    'epochs': EPOCHS // 2,  # First half with frozen base
    'callbacks': [checkpoint, early_stopping, reduce_lr],
    'verbose': 1
}

# Add class weights only if calculated
if class_weights is not None:
    fit_kwargs['class_weight'] = class_weights

history1 = model.fit(
    train_data,
    validation_data=val_data,
    **fit_kwargs
)

# -----------------------
# TRAINING PHASE 2: Fine-tune base model
# -----------------------
print("\nüîÑ Phase 2: Fine-tuning base model...")
print("=" * 50)

# Unfreeze some layers for fine-tuning
base_model.trainable = True
# Freeze early layers, fine-tune later layers
for layer in base_model.layers[:-20]:  # Freeze all but last 20 layers
    layer.trainable = False

# Recompile with lower learning rate for fine-tuning
model.compile(
    optimizer=tf.keras.optimizers.Adam(
        learning_rate=0.00005),  # Lower LR for fine-tuning
    loss="binary_crossentropy",
    metrics=["accuracy", "precision", "recall"]
)

print(
    f"‚úÖ Trainable layers: {sum([1 for layer in base_model.layers if layer.trainable])}")

# Calculate starting epoch for phase 2
initial_epoch_phase2 = len(history1.history['accuracy'])
total_epochs_phase2 = initial_epoch_phase2 + (EPOCHS // 2)

# Prepare fit arguments for phase 2
fit_kwargs2 = {
    'epochs': total_epochs_phase2,  # Total epochs including phase 1
    'callbacks': [checkpoint, early_stopping, reduce_lr],
    'verbose': 1,
    'initial_epoch': initial_epoch_phase2
}

# Add class weights only if calculated
if class_weights is not None:
    fit_kwargs2['class_weight'] = class_weights

history2 = model.fit(
    train_data,
    validation_data=val_data,
    **fit_kwargs2
)

# Combine histories
history = {
    'accuracy': history1.history['accuracy'] + history2.history['accuracy'],
    'val_accuracy': history1.history['val_accuracy'] + history2.history['val_accuracy'],
    'loss': history1.history['loss'] + history2.history['loss'],
    'val_loss': history1.history['val_loss'] + history2.history['val_loss']
}

# -----------------------
# SAVE FINAL MODEL
# -----------------------
model.save(MODEL_PATH)
print("\n" + "=" * 50)
print("‚úÖ Model trained and saved as", MODEL_PATH)
print(f"‚úÖ Final Training Accuracy: {history['accuracy'][-1]:.4f}")
print(f"‚úÖ Final Validation Accuracy: {history['val_accuracy'][-1]:.4f}")
print(f"‚úÖ Best Validation Accuracy: {max(history['val_accuracy']):.4f}")
print("=" * 50)
print("\nüéâ Training complete! Your model is ready to analyze images.")
print("üí° Run 'python predict.py <image_path>' to test on images.")
print("üí° Run 'python test.py' to evaluate model performance.")
